[0m[[0m[0mdebug[0m] [0m[0m> Exec(;Test/compile; collectAnalyses, None, Some(CommandSource(network-1)))[0m
[0m[[0m[0mdebug[0m] [0m[0munmatched Processing event for requestId None: None[0m
[0m[[0m[0mdebug[0m] [0m[0munmatched Done event for requestId None: None[0m
[0m[[0m[0mdebug[0m] [0m[0m> Exec(Test/compile, None, Some(CommandSource(network-1)))[0m
[0m[[0m[0mdebug[0m] [0m[0munmatched Processing event for requestId None: None[0m
[0m[[0m[0mdebug[0m] [0m[0mEvaluating tasks: Test / compile[0m
[0m[[0m[0mdebug[0m] [0m[0mRunning task... Cancel: Signal, check cycles: false, forcegc: true[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/taskStart, {"taskId":{"id":"5","parents":[]},"eventTime":1646524358414,"message":"Compiling root","dataKind":"compile-task","data":{"target":{"uri":"file:/C:/Users/98jjm/OneDrive/Documents/_VSCODE/Cognizant_Use_Case/cognizantUseCase/#root/Compile"}}})[0m
[0m[[0m[0minfo[0m] [0m[0mcompiling 1 Scala source to C:\Users\98jjm\OneDrive\Documents\_VSCODE\Cognizant_Use_Case\cognizantUseCase\target\scala-2.11\classes ...[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":3,"message":"compiling 1 Scala source to C:\\Users\\98jjm\\OneDrive\\Documents\\_VSCODE\\Cognizant_Use_Case\\cognizantUseCase\\target\\scala-2.11\\classes ..."})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/publishDiagnostics, {"textDocument":{"uri":"file:///C:/Users/98jjm/OneDrive/Documents/_VSCODE/Cognizant_Use_Case/cognizantUseCase/src/main/scala/example/main.scala"},"buildTarget":{"uri":"file:/C:/Users/98jjm/OneDrive/Documents/_VSCODE/Cognizant_Use_Case/cognizantUseCase/#root/Compile"},"diagnostics":[{"range":{"start":{"line":25,"character":14},"end":{"line":25,"character":15}},"severity":1,"source":"sbt","message":"not found: value SparkSession"}],"reset":false})[0m
[0m[[0m[31merror[0m] [0m[0mC:\Users\98jjm\OneDrive\Documents\_VSCODE\Cognizant_Use_Case\cognizantUseCase\src\main\scala\example\main.scala:26:15: not found: value SparkSession[0m
[0m[[0m[31merror[0m] [0m[0m  val spark = SparkSession[0m
[0m[[0m[31merror[0m] [0m[0m              ^[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":1,"message":"C:\\Users\\98jjm\\OneDrive\\Documents\\_VSCODE\\Cognizant_Use_Case\\cognizantUseCase\\src\\main\\scala\\example\\main.scala:26:15: not found: value SparkSession"})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":1,"message":"  val spark = SparkSession"})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":1,"message":"              ^"})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/publishDiagnostics, {"textDocument":{"uri":"file:///C:/Users/98jjm/OneDrive/Documents/_VSCODE/Cognizant_Use_Case/cognizantUseCase/src/main/scala/example/main.scala"},"buildTarget":{"uri":"file:/C:/Users/98jjm/OneDrive/Documents/_VSCODE/Cognizant_Use_Case/cognizantUseCase/#root/Compile"},"diagnostics":[{"range":{"start":{"line":34,"character":23},"end":{"line":34,"character":24}},"severity":1,"source":"sbt","message":"not found: type StructType"}],"reset":false})[0m
[0m[[0m[31merror[0m] [0m[0mC:\Users\98jjm\OneDrive\Documents\_VSCODE\Cognizant_Use_Case\cognizantUseCase\src\main\scala\example\main.scala:35:24: not found: type StructType[0m
[0m[[0m[31merror[0m] [0m[0m  val mainSchema = new StructType()[0m
[0m[[0m[31merror[0m] [0m[0m                       ^[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":1,"message":"C:\\Users\\98jjm\\OneDrive\\Documents\\_VSCODE\\Cognizant_Use_Case\\cognizantUseCase\\src\\main\\scala\\example\\main.scala:35:24: not found: type StructType"})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":1,"message":"  val mainSchema = new StructType()"})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":1,"message":"                       ^"})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/publishDiagnostics, {"textDocument":{"uri":"file:///C:/Users/98jjm/OneDrive/Documents/_VSCODE/Cognizant_Use_Case/cognizantUseCase/src/main/scala/example/main.scala"},"buildTarget":{"uri":"file:/C:/Users/98jjm/OneDrive/Documents/_VSCODE/Cognizant_Use_Case/cognizantUseCase/#root/Compile"},"diagnostics":[{"range":{"start":{"line":35,"character":27},"end":{"line":35,"character":28}},"severity":1,"source":"sbt","message":"not found: value IntegerType"}],"reset":false})[0m
[0m[[0m[31merror[0m] [0m[0mC:\Users\98jjm\OneDrive\Documents\_VSCODE\Cognizant_Use_Case\cognizantUseCase\src\main\scala\example\main.scala:36:28: not found: value IntegerType[0m
[0m[[0m[31merror[0m] [0m[0m      .add("RecordNumber", IntegerType, true)[0m
[0m[[0m[31merror[0m] [0m[0m                           ^[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":1,"message":"C:\\Users\\98jjm\\OneDrive\\Documents\\_VSCODE\\Cognizant_Use_Case\\cognizantUseCase\\src\\main\\scala\\example\\main.scala:36:28: not found: value IntegerType"})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":1,"message":"      .add(\"RecordNumber\", IntegerType, true)"})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":1,"message":"                           ^"})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/publishDiagnostics, {"textDocument":{"uri":"file:///C:/Users/98jjm/OneDrive/Documents/_VSCODE/Cognizant_Use_Case/cognizantUseCase/src/main/scala/example/main.scala"},"buildTarget":{"uri":"file:/C:/Users/98jjm/OneDrive/Documents/_VSCODE/Cognizant_Use_Case/cognizantUseCase/#root/Compile"},"diagnostics":[{"range":{"start":{"line":36,"character":22},"end":{"line":36,"character":23}},"severity":1,"source":"sbt","message":"not found: value IntegerType"}],"reset":false})[0m
[0m[[0m[31merror[0m] [0m[0mC:\Users\98jjm\OneDrive\Documents\_VSCODE\Cognizant_Use_Case\cognizantUseCase\src\main\scala\example\main.scala:37:23: not found: value IntegerType[0m
[0m[[0m[31merror[0m] [0m[0m      .add("Zipcode", IntegerType, true)[0m
[0m[[0m[31merror[0m] [0m[0m                      ^[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":1,"message":"C:\\Users\\98jjm\\OneDrive\\Documents\\_VSCODE\\Cognizant_Use_Case\\cognizantUseCase\\src\\main\\scala\\example\\main.scala:37:23: not found: value IntegerType"})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":1,"message":"      .add(\"Zipcode\", IntegerType, true)"})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":1,"message":"                      ^"})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/publishDiagnostics, {"textDocument":{"uri":"file:///C:/Users/98jjm/OneDrive/Documents/_VSCODE/Cognizant_Use_Case/cognizantUseCase/src/main/scala/example/main.scala"},"buildTarget":{"uri":"file:/C:/Users/98jjm/OneDrive/Documents/_VSCODE/Cognizant_Use_Case/cognizantUseCase/#root/Compile"},"diagnostics":[{"range":{"start":{"line":37,"character":26},"end":{"line":37,"character":27}},"severity":1,"source":"sbt","message":"not found: value StringType"}],"reset":false})[0m
[0m[[0m[31merror[0m] [0m[0mC:\Users\98jjm\OneDrive\Documents\_VSCODE\Cognizant_Use_Case\cognizantUseCase\src\main\scala\example\main.scala:38:27: not found: value StringType[0m
[0m[[0m[31merror[0m] [0m[0m      .add("ZipCodeType", StringType, true)[0m
[0m[[0m[31merror[0m] [0m[0m                          ^[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":1,"message":"C:\\Users\\98jjm\\OneDrive\\Documents\\_VSCODE\\Cognizant_Use_Case\\cognizantUseCase\\src\\main\\scala\\example\\main.scala:38:27: not found: value StringType"})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":1,"message":"      .add(\"ZipCodeType\", StringType, true)"})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":1,"message":"                          ^"})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/publishDiagnostics, {"textDocument":{"uri":"file:///C:/Users/98jjm/OneDrive/Documents/_VSCODE/Cognizant_Use_Case/cognizantUseCase/src/main/scala/example/main.scala"},"buildTarget":{"uri":"file:/C:/Users/98jjm/OneDrive/Documents/_VSCODE/Cognizant_Use_Case/cognizantUseCase/#root/Compile"},"diagnostics":[{"range":{"start":{"line":53,"character":9},"end":{"line":53,"character":10}},"severity":1,"source":"sbt","message":"value Parquet is not a member of org.apache.spark.sql.DataFrameWriter[org.apache.spark.sql.Row]\npossible cause: maybe a semicolon is missing before `value Parquet'?"}],"reset":false})[0m
[0m[[0m[31merror[0m] [0m[0mC:\Users\98jjm\OneDrive\Documents\_VSCODE\Cognizant_Use_Case\cognizantUseCase\src\main\scala\example\main.scala:54:10: value Parquet is not a member of org.apache.spark.sql.DataFrameWriter[org.apache.spark.sql.Row][0m
[0m[[0m[31merror[0m] [0m[0mpossible cause: maybe a semicolon is missing before `value Parquet'?[0m
[0m[[0m[31merror[0m] [0m[0m        .Parquet(s"$folderPath")[0m
[0m[[0m[31merror[0m] [0m[0m         ^[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":1,"message":"C:\\Users\\98jjm\\OneDrive\\Documents\\_VSCODE\\Cognizant_Use_Case\\cognizantUseCase\\src\\main\\scala\\example\\main.scala:54:10: value Parquet is not a member of org.apache.spark.sql.DataFrameWriter[org.apache.spark.sql.Row]\npossible cause: maybe a semicolon is missing before `value Parquet'?"})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":1,"message":"        .Parquet(s\"$folderPath\")"})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":1,"message":"         ^"})[0m
[0m[[0m[31merror[0m] [0m[0m6 errors found[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":1,"message":"6 errors found"})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/publishDiagnostics, {"textDocument":{"uri":"file:///C:/Users/98jjm/OneDrive/Documents/_VSCODE/Cognizant_Use_Case/cognizantUseCase/src/main/scala/example/main.scala"},"buildTarget":{"uri":"file:/C:/Users/98jjm/OneDrive/Documents/_VSCODE/Cognizant_Use_Case/cognizantUseCase/#root/Compile"},"diagnostics":[{"range":{"start":{"line":25,"character":14},"end":{"line":25,"character":15}},"severity":1,"source":"sbt","message":"not found: value SparkSession"},{"range":{"start":{"line":34,"character":23},"end":{"line":34,"character":24}},"severity":1,"source":"sbt","message":"not found: type StructType"},{"range":{"start":{"line":35,"character":27},"end":{"line":35,"character":28}},"severity":1,"source":"sbt","message":"not found: value IntegerType"},{"range":{"start":{"line":36,"character":22},"end":{"line":36,"character":23}},"severity":1,"source":"sbt","message":"not found: value IntegerType"},{"range":{"start":{"line":37,"character":26},"end":{"line":37,"character":27}},"severity":1,"source":"sbt","message":"not found: value StringType"},{"range":{"start":{"line":53,"character":9},"end":{"line":53,"character":10}},"severity":1,"source":"sbt","message":"value Parquet is not a member of org.apache.spark.sql.DataFrameWriter[org.apache.spark.sql.Row]\npossible cause: maybe a semicolon is missing before `value Parquet'?"}],"reset":true})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/taskFinish, {"taskId":{"id":"5","parents":[]},"eventTime":1646524358665,"message":"Compiled root","status":2,"dataKind":"compile-report","data":{"target":{"uri":"file:/C:/Users/98jjm/OneDrive/Documents/_VSCODE/Cognizant_Use_Case/cognizantUseCase/#root/Compile"},"errors":6,"warnings":0,"time":251}})[0m
[0m[[0m[0mdebug[0m] [0m[0munmatched json error for requestId None: {"code":-32603,"message":"(Compile / \u001b[31mcompileIncremental\u001b[0m) Compilation failed"}[0m
[0m[[0m[31merror[0m] [0m[0m(Compile / [31mcompileIncremental[0m) Compilation failed[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":1,"message":"(Compile / \u001b[31mcompileIncremental\u001b[0m) Compilation failed"})[0m
[0m[[0m[31merror[0m] [0m[0mTotal time: 0 s, completed Mar 5, 2022, 6:52:38 PM[0m
[0m[[0m[0mdebug[0m] [0m[0munmatched Done event for requestId None: None[0m
[0m[[0m[0mdebug[0m] [0m[0m> Exec(shell, None, None)[0m
[0m[[0m[0mdebug[0m] [0m[0mUnhandled notification received: textDocument/didClose: JsonRpcNotificationMessage(2.0, textDocument/didClose, {"textDocument":{"uri":"file:///c%3A/Users/98jjm/OneDrive/Documents/_Revature_Code/Samples/Oct2021ScalaBatch/SparkSamples/sparkscala/src/main/scala/example/readcsvdf.scala"}})[0m
[0m[[0m[0mdebug[0m] [0m[0mUnhandled notification received: textDocument/didOpen: JsonRpcNotificationMessage(2.0, textDocument/didOpen, {"textDocument":{"uri":"file:///c%3A/Users/98jjm/OneDrive/Documents/_Revature_Code/Samples/Oct2021ScalaBatch/SparkSamples/sparkscala/src/main/scala/example/readparquetdf.scala","languageId":"scala","version":1,"text":"// readparquetdf.scala\r\npackage example\r\n\r\nimport org.apache.spark.sql.SparkSession\r\n\r\nobject ParquetExample {\r\n\r\n  def main(args: Array[String]): Unit = {\r\n\r\n    val spark: SparkSession = SparkSession\r\n      .builder()\r\n      .master(\"local[1]\")\r\n      .appName(\"AjaySingala.com\")\r\n      .getOrCreate()\r\n\r\n    println(\"Define the data...\")\r\n    //  Create a Spark DataFrame from Seq object.\r\n    val data = Seq(\r\n      (\"James \", \"\", \"Smith\", \"36636\", \"M\", 3000),\r\n      (\"Michael \", \"Rose\", \"\", \"40288\", \"M\", 4000),\r\n      (\"Robert \", \"\", \"Williams\", \"42114\", \"M\", 4000),\r\n      (\"Maria \", \"Anne\", \"Jones\", \"39192\", \"F\", 4000),\r\n      (\"Jen\", \"Mary\", \"Brown\", \"\", \"F\", -1)\r\n    )\r\n\r\n    println(\"Define the schema...\")\r\n    val columns =\r\n      Seq(\"firstname\", \"middlename\", \"lastname\", \"dob\", \"gender\", \"salary\")\r\n\r\n    println(\"Create the DF...\")\r\n    import spark.sqlContext.implicits._\r\n    val df = data.toDF(columns: _*)\r\n    df.show()\r\n    df.printSchema()\r\n\r\n    // Write DataFrame to Parquet file format.\r\n    println(\"Write the DF to a Parquet file...\")\r\n    df.write.parquet(\"/tmp/output/people.parquet\")\r\n\r\n    // Read Parquet file into DataFrame.\r\n    println(\"Read the Parquet file...\")\r\n    val parqDF = spark.read.parquet(\"/tmp/output/people.parquet\")\r\n    // parqDF.printSchema()\r\n    // parqDF.show()\r\n\r\n    // Append to existing Parquet file.\r\n    println(\"Append to an existing Parquet...\")\r\n    df.write.mode(\"append\").parquet(\"/tmp/output/people.parquet\")\r\n\r\n    // Using SQL queries on Parquet.\r\n    println(\"Create View for Parquet...\")\r\n    parqDF.createOrReplaceTempView(\"ParquetTable\")\r\n    println(\"Explain the SQL statement to be exeucted on the Parquet View...\")\r\n    spark.sql(\"select * from ParquetTable where salary >= 4000\").explain()\r\n    println(\"Fetch data from the view using SQL syntax...\")\r\n    val parkSQL = spark.sql(\"select * from ParquetTable where salary >= 4000\")\r\n    parkSQL.show()\r\n    parkSQL.printSchema()\r\n\r\n    // Spark parquet partition â€“ Improving performance.\r\n    println(\"Creating parquet with partitions...\")\r\n    df.write\r\n      .partitionBy(\"gender\", \"salary\")\r\n      .parquet(\"/tmp/output/people2.parquet\")\r\n\r\n    // Execution of this query is significantly faster than the query without partition.\r\n    // It filters the data first on gender and then applies filters on salary.\r\n    println(\"Read the paritioned parquet...\")\r\n    val parqDF2 = spark.read.parquet(\"/tmp/output/people2.parquet\")\r\n    println(\"Fetch data using SQL syntax from the partitioned parquet DF...\")\r\n    parqDF2.createOrReplaceTempView(\"ParquetTable2\")\r\n    val df3 =\r\n      spark.sql(\r\n        \"select * from ParquetTable2 where gender='M' and salary >= 4000\"\r\n      )\r\n    df3.explain()\r\n    df3.printSchema()\r\n    df3.show()\r\n\r\n    // Read a specific Parquet partition.\r\n    println(\"Read data from a specifc parition...\")\r\n    val parqDF3 = spark.read.parquet(\"/tmp/output/people2.parquet/gender=M\")\r\n    parqDF3.show()\r\n  }\r\n}\r\n"}})[0m
[0m[[0m[0mdebug[0m] [0m[0mUnhandled notification received: textDocument/didClose: JsonRpcNotificationMessage(2.0, textDocument/didClose, {"textDocument":{"uri":"file:///c%3A/Users/98jjm/OneDrive/Documents/_Revature_Code/Samples/Oct2021ScalaBatch/SparkSamples/sparkscala/src/main/scala/example/readparquetdf.scala"}})[0m
[0m[[0m[0mdebug[0m] [0m[0mlsp-definition json request: {"textDocument":{"uri":"file:///c%3A/Users/98jjm/OneDrive/Documents/_VSCODE/Cognizant_Use_Case/cognizantUseCase/src/main/scala/example/main.scala"},"position":{"line":35,"character":14}}[0m
[0m[[0m[0mdebug[0m] [0m[0mlsp-definition found line:       .add("RecordNumber", IntegerType, true)[0m
