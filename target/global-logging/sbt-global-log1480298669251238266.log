[0m[[0m[0mdebug[0m] [0m[0m> Exec(collectAnalyses, None, Some(CommandSource(network-1)))[0m
[0m[[0m[0mdebug[0m] [0m[0munmatched Processing event for requestId None: None[0m
[0m[[0m[0mdebug[0m] [0m[0mUnhandled notification received: initialized: JsonRpcNotificationMessage(2.0, initialized, {})[0m
[0m[[0m[0mdebug[0m] [0m[0mEvaluating tasks: Compile / collectAnalyses[0m
[0m[[0m[0mdebug[0m] [0m[0mUnhandled notification received: textDocument/didOpen: JsonRpcNotificationMessage(2.0, textDocument/didOpen, {"textDocument":{"uri":"file:///c%3A/Users/98jjm/OneDrive/Documents/_VSCODE/Cognizant_Use_Case/cognizantUseCase/src/main/scala/example/main.scala","languageId":"scala","version":1,"text":"package example\r\n\r\n// import java.io.IOException\r\n// import scala.util.Try\r\n// // import os._\r\n\r\n// import org.apache.spark.sql.SparkSession\r\n// import java.nio.file.{Paths, Files}\r\n// import scala.sys.process._\r\n\r\nimport org.apache.spark.sql.{Row, DataFrame}\r\n// import org.apache.spark.sql.types._\r\n// import org.apache.spark.sql.functions._\r\n// import scala.collection.JavaConversions._\r\n// import org.apache.spark.sql.expressions.Window\r\n\r\n// import org.apache.hadoop.conf.Configuration;\r\n// import org.apache.hadoop.fs.FileSystem;\r\n// import org.apache.hadoop.fs.Path;\r\n// import java.io.PrintWriter;\r\n// import java.io._\r\n// import scala.collection.mutable.ListBuffer\r\n// import scala.io.Source\r\n\r\nobject Main extends App {\r\n  val spark = SparkSession\r\n    .builder()\r\n    .master(\"local[1]\")\r\n    .appName(\"Cognizant Use Case\")\r\n    .getOrCreate()\r\n\r\n  import spark.implicits._\r\n  spark.sparkContext.setLogLevel(\"ERROR\")\r\n\r\n  println(\"\\nReading the data Set...\\n\")\r\n  val parqDF1 = spark\r\n    .read\r\n    .csv(\"/user/maria_dev/example.csv\")\r\n  println(\"Done...\\n\")\r\n\r\n  def storeCSV(df: DataFrame, folderPath: String): Unit = {\r\n    if (scala.io.StdIn.readLine(\"Store in Parquet? >> (y/n)\").toLowerCase == \"y\")\r\n      df.coalesce(1)\r\n        .write\r\n        .mode(\"overwrite\")\r\n        .Parquet(s\"$folderPath\")\r\n  }\r\n}\r\n"}})[0m
[0m[[0m[0mdebug[0m] [0m[0mRunning task... Cancel: Signal, check cycles: false, forcegc: true[0m
[0m[[0m[0mdebug[0m] [0m[0manalysis location (C:\Users\98jjm\OneDrive\Documents\_VSCODE\Cognizant_Use_Case\cognizantUseCase\target\scala-2.11\zinc\inc_compile_2.11.zip,true)[0m
[0m[[0m[32msuccess[0m] [0m[0mTotal time: 0 s, completed Mar 4, 2022, 4:32:30 PM[0m
[0m[[0m[0mdebug[0m] [0m[0munmatched Done event for requestId None: None[0m
[0m[[0m[0mdebug[0m] [0m[0m> Exec(shell, None, None)[0m
